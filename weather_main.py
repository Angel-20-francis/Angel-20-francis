# -*- coding: utf-8 -*-
"""weather main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DcJwjiXH-Xjj28NfAZE8OUn_xuyViF11
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler

df=pd.read_csv('/content/weather_classification_data.csv')
df

df.head()

df.tail()

df.shape

print(df.isnull().sum())

df.describe()

df.info()

df.duplicated().sum()

df['Weather Type'].unique()

df.nunique()

df.drop('Cloud Cover',axis= 1,inplace=True)

df2=df.rename(columns={'Weather Type':'Weather classification'})
df2

"""outliers handling"""

plt.figure()
plt.boxplot(df2['Wind Speed'])
plt.title('Wind Speed Boxplot')
plt.show()

plt.figure()
plt.boxplot(df2['Temperature'])
plt.title('Temperature Boxplot')
plt.show()

plt.figure()
plt.boxplot(df2['Humidity'])
plt.title('Humidity Boxplot')
plt.show()

plt.figure()
plt.boxplot(df2['Precipitation (%)'])
plt.title('Precipitation Boxplot')
plt.show()

plt.figure()
plt.boxplot(df2['Atmospheric Pressure'])
plt.title('Atmospheric Pressure Boxplot')
plt.show()

plt.figure()
plt.boxplot(df2['Visibility (km)'])
plt.title('Visibility Boxplot')
plt.show()

plt.figure()
plt.boxplot(df2['UV Index'])
plt.title('UV Index Boxplot')
plt.show()

Q1=df["Temperature"].quantile(0.25)
Q3=df["Temperature"].quantile(0.75)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
upp_lim=Q3+1.5*IQR

outlier=[]
for i in df["Temperature"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of Temperature is :",outlier)

df["Temperature"]=df["Temperature"].clip(lower=low_lim,upper=upp_lim)

outlier=[]
for i in df["Temperature"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of is Temperature:",outlier)

Q1=df2["Wind Speed"].quantile(0.25)
Q3=df2["Wind Speed"].quantile(0.75)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
upp_lim=Q3+1.5*IQR

outlier=[]
for i in df2["Wind Speed"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of Wind Speed is :",outlier)

df2["Wind Speed"]=df2["Wind Speed"].clip(lower=low_lim,upper=upp_lim)

outlier=[]
for i in df2["Wind Speed"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of is Wind Speed:",outlier)

Q1=df2["Atmospheric Pressure"].quantile(0.25)
Q3=df2["Atmospheric Pressure"].quantile(0.75)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
upp_lim=Q3+1.5*IQR

outlier=[]
for i in df2["Atmospheric Pressure"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of Atmospheric Pressure is :",outlier)

df2["Atmospheric Pressure"]=df2["Atmospheric Pressure"].clip(lower=low_lim,upper=upp_lim)

outlier=[]
for i in df2["Atmospheric Pressure"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of is Atmospheric Pressure:",outlier)

Q1=df["Visibility (km)"].quantile(0.25)
Q3=df["Visibility (km)"].quantile(0.75)

IQR=Q3-Q1

low_lim=Q1-1.5*IQR
upp_lim=Q3+1.5*IQR

outlier=[]
for i in df["Visibility (km)"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of Visibility is :",outlier)

df2["Visibility (km)"]=df2["Visibility (km)"].clip(lower=low_lim,upper=upp_lim)

outlier=[]
for i in df2["Visibility (km)"]:
     if((i>upp_lim)or(i<low_lim)):
      outlier.append(i)
print("The outlier of Visibility is :",outlier)

"""encoding"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df2['Season'] = le.fit_transform(df2['Season'])
df2['Location'] = le.fit_transform(df2['Location'])
df2['Weather classification'] = le.fit_transform(df2['Weather classification'])

df.head()

"""scaling"""

from sklearn.preprocessing import StandardScaler

std_scaler = StandardScaler()

numerical_cols = ['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)',
                  'Atmospheric Pressure','UV Index','Visibility (km)']
std_scaler.fit(df[numerical_cols])
df2[numerical_cols] = std_scaler.transform(df2[numerical_cols])
df2.head()

"""EDA"""

corr_matrix = df[['Temperature','Humidity','Wind Speed','Atmospheric Pressure','UV Index','Precipitation (%)','Visibility (km)']].corr()
plt.figure(figsize=(14, 8))
sns.heatmap(corr_matrix, annot=True, cmap='hot', linewidths=0.5, linecolor='black', fmt=".3f")
plt.title('Correlation Heatmap', fontsize=16)
plt.show()

sns.pairplot(df2, hue='Weather classification')
plt.suptitle('Pairplot of Weather Classification')
plt.show()

plt.figure(figsize=(10,5))
plt.hist(df2['Wind Speed'],bins=20,edgecolor='black',color='red')
plt.xlabel('Wind Speed')
plt.ylabel('Frequency')
plt.title('Wind Speed  Distribution')
plt.show()

eda_df2 = df2.groupby("UV Index")["Temperature"].mean()
eda_df2.plot(kind="line", figsize=(14, 8))
plt.title('UV Index dependence on Temperature', fontsize=18)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.xlabel('UV Index', fontsize=16)
plt.ylabel('Average Temperature', fontsize=16)
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='Weather classification', data=df2)
plt.title('Distribution of Weather Classifications')
plt.xlabel('Weather Classification')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

numerical_features = ['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)', 'Atmospheric Pressure', 'UV Index', 'Visibility (km)']
for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.histplot(df2[feature], kde=True)
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')
    plt.show()

plt.figure(figsize=(10, 6))
plt.plot(df2['Temperature'])
plt.title('Temperature Trend')
plt.xlabel('Index')
plt.ylabel('Temperature')

plt.figure(figsize=(10, 6))
plt.plot(df2['Humidity'])
plt.title('Humidity Trend')
plt.xlabel('Index')
plt.ylabel('Temperature')

plt.figure(figsize=(10, 6))
plt.plot(df2['Wind Speed'])
plt.title('Wind Speed Trend')
plt.xlabel('Index')
plt.ylabel('Wind Speed')

plt.figure(figsize=(10, 6))
plt.plot(df2['Precipitation (%)'])
plt.title('Precipitation Trend')
plt.xlabel('Index')
plt.ylabel('Precipitation')

plt.figure(figsize=(10, 6))
plt.plot(df2['Atmospheric Pressure'])
plt.title('Atmospheric Pressure Trend')
plt.xlabel('Index')
plt.ylabel('Atmospheric Pressure')

plt.figure(figsize=(10, 6))
plt.plot(df2['UV Index'])
plt.title('UV Index Trend')
plt.xlabel('Index')
plt.ylabel('UV Index')

plt.figure(figsize=(10, 6))
plt.plot(df2['Visibility (km)'])
plt.title('Visibility Trend')
plt.xlabel('Index')
plt.ylabel('Visibility')

plt.show()

"""Train and Train Split"""

X = df2.drop('Weather classification', axis=1)
Y = df2['Weather classification']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

print(X.shape,X_train.shape,X_test.shape)

print(X)

print(Y)

"""MODEL SELECTION

1.RANDOM FOREST CLASSIFIER
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

rf_model = RandomForestClassifier()
rf_model.fit(X_train, Y_train)


y_pred = rf_model.predict(X_test)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

rf_model = RandomForestClassifier()
rf_model.fit(X_train, Y_train)

y_pred = rf_model.predict(X_test)

accuracy = accuracy_score(Y_test, y_pred)
precision = precision_score(Y_test, y_pred, average='weighted')
recall = recall_score(Y_test, y_pred, average='weighted')
f1 = f1_score(Y_test, y_pred, average='weighted')


print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""2.LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, f1_score

lr_model = LogisticRegression()
lr_model.fit(X_train, Y_train)

y_pred_lr = lr_model.predict(X_test)

accuracy_lr = accuracy_score(Y_test, y_pred_lr)
precision_lr = precision_score(Y_test, y_pred_lr, average='weighted')
recall_lr = recall_score(Y_test, y_pred_lr, average='weighted')
f1_lr = f1_score(Y_test, y_pred_lr, average='weighted')

print("Logistic Regression Metrics:")
print(f"Accuracy: {accuracy_lr:.2f}")
print(f"Precision: {precision_lr:.2f}")
print(f"Recall: {recall_lr:.2f}")
print(f"F1 Score: {f1_lr:.2f}")

"""3.DECISION TREE"""

from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, Y_train)

y_pred_dt = dt_model.predict(X_test)

accuracy_dt = accuracy_score(Y_test, y_pred_dt)
precision_dt = precision_score(Y_test, y_pred_dt, average='weighted')
recall_dt = recall_score(Y_test, y_pred_dt, average='weighted')
f1_dt = f1_score(Y_test, y_pred_dt, average='weighted')

print("Decision Tree Metrics:")
print(f"Accuracy: {accuracy_dt:.2f}")
print(f"Precision: {precision_dt:.2f}")
print(f"Recall: {recall_dt:.2f}")
print(f"F1 Score: {f1_dt:.2f}")

"""4.SUPPORT VECTOR MACHINE(SVM)"""

from sklearn.svm import SVC

svm_model = SVC()
svm_model.fit(X_train, Y_train)

y_pred_svm = svm_model.predict(X_test)

accuracy_svm = accuracy_score(Y_test, y_pred_svm)
precision_svm = precision_score(Y_test, y_pred_svm, average='weighted')
recall_svm = recall_score(Y_test, y_pred_svm, average='weighted')
f1_svm = f1_score(Y_test, y_pred_svm, average='weighted')

print("Support Vector Machine Metrics:")
print(f"Accuracy: {accuracy_svm:.2f}")
print(f"Precision: {precision_svm:.2f}")
print(f"Recall: {recall_svm:.2f}")
print(f"F1 Score: {f1_svm:.2f}")

"""5.K-NEAREST NEIGHBORS(KNN)"""

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier()
knn_model.fit(X_train, Y_train)

y_pred_knn = knn_model.predict(X_test)

accuracy_knn = accuracy_score(Y_test, y_pred_knn)
precision_knn = precision_score(Y_test, y_pred_knn, average='weighted')
recall_knn = recall_score(Y_test, y_pred_knn, average='weighted')
f1_knn = f1_score(Y_test, y_pred_knn, average='weighted')

print("K-Nearest Neighbors Metrics:")
print(f"Accuracy: {accuracy_knn:.2f}")
print(f"Precision: {precision_knn:.2f}")
print(f"Recall: {recall_knn:.2f}")
print(f"F1 Score: {f1_knn:.2f}")

"""6.ARTIFICIAL NEURAL NETWORK(ANN)"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))
model.add(Dense(32, activation='relu'))
model.add(Dense(len(np.unique(Y)), activation='softmax'))


model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


model.fit(X_train, Y_train, epochs=10, batch_size=32, validation_data=(X_test, Y_test))


loss, accuracy_ann = model.evaluate(X_test, Y_test)
print("Artificial Neural Network Metrics:")
print(f"Accuracy: {accuracy_ann:.2f}")


y_pred_ann_probs = model.predict(X_test)
y_pred_ann = np.argmax(y_pred_ann_probs, axis=1)

"""7.CONVOLUTIONAL NEURAL NETWORK(CNN)"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten

X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_cnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)

model_cnn = Sequential()
model_cnn.add(Conv1D(32, 3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))
model_cnn.add(MaxPooling1D(2))
model_cnn.add(Flatten())
model_cnn.add(Dense(64, activation='relu'))
model_cnn.add(Dense(len(np.unique(Y)), activation='softmax'))

model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model_cnn.fit(X_train_cnn, Y_train, epochs=10, batch_size=32, validation_data=(X_test_cnn, Y_test))


loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test_cnn, Y_test)
print("Convolutional Neural Network Metrics:")
print(f"Accuracy: {accuracy_cnn:.2f}")

"""8.RECURRENT NEURAL NETWORK(RNN)"""

from tensorflow.keras.layers import SimpleRNN

X_train_rnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_rnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)

model_rnn = Sequential()
model_rnn.add(SimpleRNN(64, activation='relu', input_shape=(X_train_rnn.shape[1], 1)))
model_rnn.add(Dense(32, activation='relu'))
model_rnn.add(Dense(len(np.unique(Y)), activation='softmax'))

model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model_rnn.fit(X_train_rnn, Y_train, epochs=10, batch_size=32, validation_data=(X_test_rnn, Y_test))

loss_rnn, accuracy_rnn = model_rnn.evaluate(X_test_rnn, Y_test)
print("Recurrent Neural Network Metrics:")
print(f"Accuracy: {accuracy_rnn:.2f}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from scipy.stats import randint

model= RandomForestClassifier()
param_dist = {'n_estimators': randint(100, 200),

              'max_depth': [None, 10, 20, 30],
              'min_samples_split': randint(2, 10),
'min_samples_leaf': [1, 2, 4]
}

Random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5)
Random_search.fit(X_train, Y_train)

best_params = Random_search.best_params_
best_model = Random_search.best_estimator_
print("Best Parameters:", best_params)

y_pred_best = best_model.predict(X_test)

accuracy_best = accuracy_score(Y_test, y_pred_best)
precision_best = precision_score(Y_test, y_pred_best, average='weighted')
recall_best = recall_score(Y_test, y_pred_best, average='weighted')
f1_best = f1_score(Y_test, y_pred_best, average='weighted')

print("Best Model Metrics:")
print(f"Accuracy: {accuracy_best:.2f}")
print(f"Precision: {precision_best:.2f}")
print(f"Recall: {recall_best:.2f}")
print(f"F1 Score: {f1_best:.2f}")

"""MODEL COMPARISON"""

models = ['Random Forest', 'Logistic Regression', 'Decision Tree', 'SVM', 'KNN', 'ANN', 'CNN', 'RNN']
accuracies = [accuracy, accuracy_lr, accuracy_dt, accuracy_svm, accuracy_knn, accuracy_ann, accuracy_cnn, accuracy_rnn]

plt.figure(figsize=(10, 6))
plt.bar(models, accuracies)
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Model Comparison')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

import pickle

# Assuming 'rf_model' is the best performing model
filename = 'weather_model.pkl'
pickle.dump(rf_model, open(filename, 'wb'))

# prompt: scaler.pkl

import pickle

# Assuming 'std_scaler' is the scaler object you want to save
filename = 'scaler.pkl'
pickle.dump(std_scaler, open(filename, 'wb'))

import pickle

# Assuming 'model' is your trained model
filename = 'app.pickle'
pickle.dump(model, open(filename, 'wb')) # Changed best_rf_model to model